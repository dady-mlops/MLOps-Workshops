import os
import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage
import murnitur
from murnitur import Guard, GuardConfig, log
from murnitur.guard import RuleSet

# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑–º—ñ–Ω–Ω–∏—Ö —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞
MURNITUR_API_KEY = os.getenv("MURNITUR_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_API_BASE = os.getenv("OPENAI_API_BASE", "https://t5-or-phi-model.apps.spodarets.com/v1")
MODEL_NAME = os.getenv("MODEL_NAME", "DevOpsLLM")

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è Murnitur
murnitur.set_api_key(MURNITUR_API_KEY)
murnitur.init(project_name="MLOps", enabled_instruments=["openai", "langchain"])

config = GuardConfig(api_key=OPENAI_API_KEY, provider="openai", group="MLOps-workshop")

# –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è –Ω–∞–±–æ—Ä—ñ–≤ –ø—Ä–∞–≤–∏–ª –¥–ª—è –≤—Ö—ñ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö
input_rulesets: list[RuleSet] = [
    {
        "rules": [
            {
                "metric": "input_pii",
                "operator": "contains",
                "value": ["financial_info", "email", "ssn"],
            }
        ],
        "action": {
            "type": "OVERRIDE",
            "fallback": "–Ø –Ω–µ –º–æ–∂—É –æ–±—Ä–æ–±–ª—è—Ç–∏ –∑–∞–ø–∏—Ç–∏, —â–æ –º—ñ—Å—Ç—è—Ç—å –æ—Å–æ–±–∏—Å—Ç—É —ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ü—ñ–π–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é ü§ê",
        },
    },
    {
        "rules": [
            {
                "metric": "prompt_injection",
                "operator": "contains",
                "value": [
                    "simple_instruction",
                    "instruction_override",
                    "impersonation",
                    "personal_information_request"
                ],
            }
        ],
        "action": {
            "type": "OVERRIDE",
            "fallback": "–í–∏–±–∞—á—Ç–µ, —è –Ω–µ –º–æ–∂—É –¥–æ–ø–æ–º–æ–≥—Ç–∏ –∑ —Ü–∏–º –∑–∞–ø–∏—Ç–æ–º.",
        },
    },
]

# –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è –Ω–∞–±–æ—Ä—ñ–≤ –ø—Ä–∞–≤–∏–ª –¥–ª—è –≤–∏—Ö—ñ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö
output_rulesets: list[RuleSet] = [
    {
        "rules": [
            {
                "metric": "pii",
                "operator": "contains",
                "value": ["financial_info", "email", "ssn"],
            }
        ],
        "action": {
            "type": "OVERRIDE",
            "fallback": "–Ø –Ω–µ –º–æ–∂—É –Ω–∞–¥–∞–≤–∞—Ç–∏ –æ—Å–æ–±–∏—Å—Ç—É —ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ü—ñ–π–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é ü§ê",
        },
    },
]

# –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –æ–±—Ä–æ–±–∫–∏ –∑–∞–ø–∏—Ç—É —Ç–∞ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –≤—ñ–¥ –º–æ–¥–µ–ª—ñ
def process_query(query: str, model: ChatOpenAI):
    try:
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –≤—Ö—ñ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö
        input_check = Guard.shield({"input": query}, input_rulesets, config)
        if input_check.triggered:
            return input_check.text, True

        # –û—Ç—Ä–∏–º–∞–Ω–Ω—è –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –≤—ñ–¥ –º–æ–¥–µ–ª—ñ
        response = model.invoke([HumanMessage(content=query)])

        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –≤–∏—Ö—ñ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö
        output_check = Guard.shield({"output": response.content}, output_rulesets, config)
        if output_check.triggered:
            return output_check.text, True

        # –õ–æ–≥—É–≤–∞–Ω–Ω—è —É—Å–ø—ñ—à–Ω–æ—ó –≤–∑–∞—î–º–æ–¥—ñ—ó
        log("Successful_Interaction", {"input": query, "output": response.content})

        return response.content, False
    except Exception as e:
        log("Error", {"input": query, "error": str(e)})
        return f"–°—Ç–∞–ª–∞—Å—è –ø–æ–º–∏–ª–∫–∞: {str(e)}", True

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è Streamlit
st.set_page_config(page_title="DevOpsLLM –ß–∞—Ç", page_icon="üí¨")
st.title("DevOpsLLM –ß–∞—Ç")

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –º–æ–¥–µ–ª—ñ
@st.cache_resource
def get_model():
    return ChatOpenAI(
        model_name=MODEL_NAME,
        openai_api_base=OPENAI_API_BASE,
        openai_api_key=OPENAI_API_KEY
    )

model = get_model()

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —ñ—Å—Ç–æ—Ä—ñ—ó —á–∞—Ç—É
if "messages" not in st.session_state:
    st.session_state.messages = []

# –í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è —ñ—Å—Ç–æ—Ä—ñ—ó —á–∞—Ç—É
for message in st.session_state.messages:
    if isinstance(message, HumanMessage):
        st.chat_message("user").write(message.content)
    elif isinstance(message, AIMessage):
        st.chat_message("assistant").write(message.content)

# –ü–æ–ª–µ –≤–≤–µ–¥–µ–Ω–Ω—è –¥–ª—è –Ω–æ–≤–æ–≥–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è
user_input = st.chat_input("–í–≤–µ–¥—ñ—Ç—å –≤–∞—à–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è:")

if user_input:
    # –î–æ–¥–∞–≤–∞–Ω–Ω—è –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –¥–æ —ñ—Å—Ç–æ—Ä—ñ—ó
    st.session_state.messages.append(HumanMessage(content=user_input))
    st.chat_message("user").write(user_input)

    # –û–±—Ä–æ–±–∫–∞ –∑–∞–ø–∏—Ç—É –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º –º–æ–¥–µ–ª—ñ —Ç–∞ Murnitur
    with st.spinner("DevOpsLLM –¥—É–º–∞—î..."):
        response, is_warning = process_query(user_input, model)

    if is_warning:
        st.warning(response)
    else:
        # –î–æ–¥–∞–≤–∞–Ω–Ω—è –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –º–æ–¥–µ–ª—ñ –¥–æ —ñ—Å—Ç–æ—Ä—ñ—ó
        st.session_state.messages.append(AIMessage(content=response))
        st.chat_message("assistant").write(response)